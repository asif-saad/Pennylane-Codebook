{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device('default.qubit', wires=1)\n",
    "# Define the quantum circuit with a parameterized RY gate\n",
    "@qml.qnode(dev)\n",
    "def circuit_to_differentiate(theta):\n",
    "    \"\"\"Quantum circuit we want to differentiate.\n",
    "\n",
    "    Args:\n",
    "        theta (float): parameter of the circuit with respect to which we differentiate.\n",
    "\n",
    "    Returns:\n",
    "        (np.tensor): a numpy tensor of 1 element corresponding to the expectation value of Z\n",
    "    \"\"\"\n",
    "    ##################\n",
    "    # YOUR CODE HERE #\n",
    "    ##################\n",
    "    qml.RY(theta, wires=0)\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "# Define the parameter-shift rule function\n",
    "def parameter_shift_rule(theta):\n",
    "    \"\"\"Function that applies the parameter shift rule to `circuit_to_differentiate` with respect to the parameter theta.\n",
    "\n",
    "    Args:\n",
    "        theta (float): parameter of the circuit with respect to which we differentiate.\n",
    "\n",
    "    Returns:\n",
    "        (np.tensor): a numpy tensor of 1 element corresponding to the derivative of the circuit with respect to theta.\n",
    "    \"\"\"    \n",
    "    ##################\n",
    "    # YOUR CODE HERE #\n",
    "    ##################\n",
    "    shift = np.pi / 2\n",
    "    forward = circuit_to_differentiate(theta + shift)  # f(theta + pi/2)\n",
    "    backward = circuit_to_differentiate(theta - shift)  # f(theta - pi/2)\n",
    "    \n",
    "    # Compute the gradient\n",
    "    gradient = 0.5 * (forward - backward)\n",
    "    return gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the built-in parameter-shift rule function\n",
    "def parameter_shift_rule_built_in(circuit, theta):\n",
    "    \"\"\"Function that applies the PennyLane built-in parameter shift rule to a specific circuit with respect to the parameter theta.\n",
    "\n",
    "    Args:\n",
    "        circuit (qml.QNode): quantum circuit we want to differentiate.\n",
    "        theta (float): parameter of the circuit with respect to which we differentiate.\n",
    "\n",
    "    Returns:\n",
    "        (np.tensor): a numpy tensor of 1 element corresponding to the derivative of the circuit with respect to theta.\n",
    "    \"\"\"  \n",
    "    ##################\n",
    "    # YOUR CODE HERE #\n",
    "    ##################\n",
    "    gradient_fn = qml.gradients.param_shift(circuit)\n",
    "    gradient = gradient_fn(theta)\n",
    "    return gradient\n",
    "# Define the built-in classical_jacobian function\n",
    "def jacobian_built_in(circuit, theta):\n",
    "    \"\"\"Function that applies the PennyLane built-in jacobian method to a specific circuit with respect to the parameter theta.\n",
    "\n",
    "    Args:\n",
    "        circuit (qml.QNode): quantum circuit we want to differentiate.\n",
    "        theta (float): parameter of the circuit with respect to which we differentiate.\n",
    "\n",
    "    Returns:\n",
    "        (np.tensor): a numpy tensor of 1 element corresponding to the derivative of the circuit with respect to theta.\n",
    "    \"\"\"  \n",
    "    ##################\n",
    "    # YOUR CODE HERE #\n",
    "    ################## \n",
    "    jacobian_fn = qml.jacobian(circuit)\n",
    "    jacobian = jacobian_fn(theta)\n",
    "    return jacobian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_optimization(quantum_circuit,initial_theta, learning_rate, max_iterations):\n",
    "    \"\"\"\n",
    "    Performs Gradient Descent optimization to find the optimal parameter theta\n",
    "    for a quantum circuit to minimize its output expectation value.\n",
    "\n",
    "    Args:\n",
    "        quantum_circuit (qml.QNode): A quantum circuit that depends of a parameter.\n",
    "        initial_theta (np.array): An array with the initial value of the trainable parameter theta.\n",
    "        learning_rate (float): Learning rate for the gradient descent update.\n",
    "        max_iterations (int): Maximum number of iterations for the optimization.\n",
    "\n",
    "    Returns:\n",
    "        (np.array): A numpy array of 1 element corresponding to the optimized parameter theta.\n",
    "    \"\"\"\n",
    "    ##################\n",
    "    # YOUR CODE HERE #\n",
    "    ##################\n",
    "    theta = initial_theta\n",
    "    for i in range(max_iterations):\n",
    "        gradient = qml.grad(quantum_circuit)(theta)\n",
    "        theta = theta - learning_rate * gradient\n",
    "        \n",
    "        print(f\"Iteration {i+1}: theta = {theta}, f(theta) = {quantum_circuit(theta)}\")\n",
    "\n",
    "    return theta\n",
    "    \n",
    "\n",
    "optimized_theta=gradient_descent_optimization(circuit,np.array(0.1,requires_grad=True), 0.3, 50)\n",
    "print(f\"Optimized theta using Gradient Descent: {optimized_theta}\")\n",
    "print(f\"Expectation value of quantum circuit at optimized theta: {circuit(optimized_theta)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_optimization_built_in(quantum_circuit,initial_theta, learning_rate, max_iterations):\n",
    "    \"\"\"\n",
    "    Implements Gradient Descent optimization method of PennyLane to find the optimal parameter theta\n",
    "    for a quantum circuit to minimize its output expectation value.\n",
    "\n",
    "    Args:\n",
    "        quantum_circuit (qml.QNode): A quantum circuit that depends of a parameter.\n",
    "        initial_theta (np.array): An array with the initial value of the trainable parameter theta.\n",
    "        learning_rate (float): Learning rate for the gradient descent update.\n",
    "        max_iterations (int): Maximum number of iterations for the optimization.\n",
    "\n",
    "    Returns:\n",
    "        (np.array): A numpy array of 1 element corresponding to the optimized parameter theta.\n",
    "    \"\"\"\n",
    "    ##################\n",
    "    # YOUR CODE HERE #\n",
    "    ##################\n",
    "    opt = qml.GradientDescentOptimizer(stepsize= learning_rate)\n",
    "    theta = initial_theta\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        theta = opt.step(quantum_circuit,theta)\n",
    "        print(f\"Iteration {i+1}: theta = {theta}, f(theta) = {quantum_circuit(theta)}\")\n",
    "\n",
    "    return theta\n",
    "\n",
    "optimized_theta=gradient_descent_optimization_built_in(circuit,np.array(0.1,requires_grad=True), 0.3, 50)\n",
    "print(f\"Optimized theta using built-in Gradient Descent: {optimized_theta}\")\n",
    "print(f\"Expectation value of quantum circuit at optimized theta: {circuit(optimized_theta)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(observable,params):\n",
    "    \"\"\"Computes the cost function we want to minimize.\n",
    "\n",
    "    Args:\n",
    "        observable (qml.Hamiltonian): a pennylane Hamiltonian whose expectation value we want to measure.\n",
    "        params(np.array): an array with the trainable parameters of the ansatz.\n",
    "\n",
    "    Returns:\n",
    "        (np.tensor): a numpy tensor of 1 element corresponding to the cost function value\n",
    "    \"\"\"\n",
    "    return strongly_entangling_ansatz(observable,params)\n",
    "\n",
    "def optimizer(observable,params):\n",
    "    \"\"\"Updates the parameters to minimize the cost function value.\n",
    "\n",
    "    Args:\n",
    "        observable (qml.Hamiltonian): a pennylane Hamiltonian whose expectation value we want to measure.\n",
    "        params(np.array): an array with the trainable parameters of the ansatz.\n",
    "\n",
    "    Returns:\n",
    "        (np.array): an array with the optimized trainable parameters.\n",
    "    \"\"\"\n",
    "    def cost_fn(weights):\n",
    "        return cost_function(observable, weights)\n",
    "\n",
    "    max_steps = 100\n",
    "    opt = qml.AdamOptimizer(0.1)  \n",
    "\n",
    "    for _ in range(max_steps):\n",
    "        # update the weights by one optimizer step\n",
    "        params = opt.step(cost_fn, params)\n",
    "    return params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
